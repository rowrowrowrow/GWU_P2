{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.1/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.1/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.1/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrosenbloom/anaconda3/envs/dev/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.metrics import classification_report\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Series Code</th>\n",
       "      <th>1973 [YR1973]</th>\n",
       "      <th>1974 [YR1974]</th>\n",
       "      <th>1975 [YR1975]</th>\n",
       "      <th>1976 [YR1976]</th>\n",
       "      <th>1977 [YR1977]</th>\n",
       "      <th>1978 [YR1978]</th>\n",
       "      <th>...</th>\n",
       "      <th>2013 [YR2013]</th>\n",
       "      <th>2014 [YR2014]</th>\n",
       "      <th>2015 [YR2015]</th>\n",
       "      <th>2016 [YR2016]</th>\n",
       "      <th>2017 [YR2017]</th>\n",
       "      <th>2018 [YR2018]</th>\n",
       "      <th>2019 [YR2019]</th>\n",
       "      <th>2020 [YR2020]</th>\n",
       "      <th>2021 [YR2021]</th>\n",
       "      <th>2022 [YR2022]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>Adolescent fertility rate (births per 1,000 wo...</td>\n",
       "      <td>SP.ADO.TFRT</td>\n",
       "      <td>68.608</td>\n",
       "      <td>70.631</td>\n",
       "      <td>72.626</td>\n",
       "      <td>74.274</td>\n",
       "      <td>75.771</td>\n",
       "      <td>75.957</td>\n",
       "      <td>...</td>\n",
       "      <td>69.167</td>\n",
       "      <td>67.791</td>\n",
       "      <td>65.395</td>\n",
       "      <td>61.852</td>\n",
       "      <td>57.783</td>\n",
       "      <td>51.029</td>\n",
       "      <td>46.153</td>\n",
       "      <td>39.866</td>\n",
       "      <td>39.065</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>Agriculture, forestry, and fishing, value adde...</td>\n",
       "      <td>NV.AGR.TOTL.ZS</td>\n",
       "      <td>11.9525224881086</td>\n",
       "      <td>10.2308377488651</td>\n",
       "      <td>6.5839104917193</td>\n",
       "      <td>8.15217071197931</td>\n",
       "      <td>8.0871421139688</td>\n",
       "      <td>7.5044274778029</td>\n",
       "      <td>...</td>\n",
       "      <td>6.05291843670451</td>\n",
       "      <td>6.71270351428559</td>\n",
       "      <td>5.1566859021408</td>\n",
       "      <td>6.26456582010254</td>\n",
       "      <td>5.23162237725058</td>\n",
       "      <td>4.53787889681146</td>\n",
       "      <td>5.3185559967348</td>\n",
       "      <td>6.12846695022316</td>\n",
       "      <td>7.13154104672929</td>\n",
       "      <td>6.44416917103214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>Annual freshwater withdrawals, total (% of int...</td>\n",
       "      <td>ER.H2O.FWTL.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>9.45205479452055</td>\n",
       "      <td>9.46970620044521</td>\n",
       "      <td>9.48735760633562</td>\n",
       "      <td>...</td>\n",
       "      <td>12.9075342465753</td>\n",
       "      <td>12.9075342465753</td>\n",
       "      <td>12.9075342465753</td>\n",
       "      <td>12.9075342465753</td>\n",
       "      <td>12.9075342465753</td>\n",
       "      <td>12.9075342465753</td>\n",
       "      <td>12.9075342465753</td>\n",
       "      <td>12.9075342465753</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>Births attended by skilled health staff (% of ...</td>\n",
       "      <td>SH.STA.BRTC.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>99.6</td>\n",
       "      <td>99.6</td>\n",
       "      <td>98.4</td>\n",
       "      <td>93.9</td>\n",
       "      <td>99.5</td>\n",
       "      <td>99.6</td>\n",
       "      <td>98.8</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>CO2 emissions (metric tons per capita)</td>\n",
       "      <td>EN.ATM.CO2E.PC</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>4.34225013023383</td>\n",
       "      <td>4.20911189491323</td>\n",
       "      <td>4.30191380564475</td>\n",
       "      <td>4.20181586904703</td>\n",
       "      <td>4.07011168693629</td>\n",
       "      <td>3.97565074444479</td>\n",
       "      <td>3.74202981162433</td>\n",
       "      <td>3.4056175404138</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name Country Code  \\\n",
       "0    Argentina          ARG   \n",
       "1    Argentina          ARG   \n",
       "2    Argentina          ARG   \n",
       "3    Argentina          ARG   \n",
       "4    Argentina          ARG   \n",
       "\n",
       "                                         Series Name     Series Code  \\\n",
       "0  Adolescent fertility rate (births per 1,000 wo...     SP.ADO.TFRT   \n",
       "1  Agriculture, forestry, and fishing, value adde...  NV.AGR.TOTL.ZS   \n",
       "2  Annual freshwater withdrawals, total (% of int...  ER.H2O.FWTL.ZS   \n",
       "3  Births attended by skilled health staff (% of ...  SH.STA.BRTC.ZS   \n",
       "4             CO2 emissions (metric tons per capita)  EN.ATM.CO2E.PC   \n",
       "\n",
       "      1973 [YR1973]     1974 [YR1974]    1975 [YR1975]     1976 [YR1976]  \\\n",
       "0            68.608            70.631           72.626            74.274   \n",
       "1  11.9525224881086  10.2308377488651  6.5839104917193  8.15217071197931   \n",
       "2                ..                ..               ..  9.45205479452055   \n",
       "3                ..                ..               ..                ..   \n",
       "4                ..                ..               ..                ..   \n",
       "\n",
       "      1977 [YR1977]     1978 [YR1978]  ...     2013 [YR2013]  \\\n",
       "0            75.771            75.957  ...            69.167   \n",
       "1   8.0871421139688   7.5044274778029  ...  6.05291843670451   \n",
       "2  9.46970620044521  9.48735760633562  ...  12.9075342465753   \n",
       "3                ..                ..  ...                97   \n",
       "4                ..                ..  ...  4.34225013023383   \n",
       "\n",
       "      2014 [YR2014]     2015 [YR2015]     2016 [YR2016]     2017 [YR2017]  \\\n",
       "0            67.791            65.395            61.852            57.783   \n",
       "1  6.71270351428559   5.1566859021408  6.26456582010254  5.23162237725058   \n",
       "2  12.9075342465753  12.9075342465753  12.9075342465753  12.9075342465753   \n",
       "3              99.6              99.6              98.4              93.9   \n",
       "4  4.20911189491323  4.30191380564475  4.20181586904703  4.07011168693629   \n",
       "\n",
       "      2018 [YR2018]     2019 [YR2019]     2020 [YR2020]     2021 [YR2021]  \\\n",
       "0            51.029            46.153            39.866            39.065   \n",
       "1  4.53787889681146   5.3185559967348  6.12846695022316  7.13154104672929   \n",
       "2  12.9075342465753  12.9075342465753  12.9075342465753                ..   \n",
       "3              99.5              99.6              98.8                ..   \n",
       "4  3.97565074444479  3.74202981162433   3.4056175404138                ..   \n",
       "\n",
       "      2022 [YR2022]  \n",
       "0                ..  \n",
       "1  6.44416917103214  \n",
       "2                ..  \n",
       "3                ..  \n",
       "4                ..  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in the raw data from WorldBank\n",
    "data_df = pd.read_csv(\n",
    "    Path(\"./Resources/03c00fd0-1cf9-46e8-aa22-40e2b0adbc27_Data.csv\"), \n",
    ")\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need these two columns\n",
    "data_df = data_df.drop(columns=['Country Name','Series Code']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by country and then by series name so we can provide per-country analysis\n",
    "grouped = data_df.groupby([\n",
    "    'Country Code',\n",
    "    'Series Name'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to return all the data for the aggregation so just return the data during aggregation\n",
    "grouped = grouped.agg(lambda x: x)\n",
    "\n",
    "# Replace the default missing data value with NaN\n",
    "grouped = grouped.replace('..', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining 266\n",
      "Remaining 265\n",
      "Remaining 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
      "/var/folders/s7/5vbrzq7x741_dp271_qgj7wc0000gn/T/ipykernel_25416/2031278900.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining 263\n",
      "Remaining 262\n",
      "Remaining 261\n",
      "Remaining 260\n",
      "Remaining 259\n",
      "Remaining 258\n",
      "Remaining 257\n",
      "Remaining 256\n",
      "Remaining 255\n",
      "Remaining 254\n",
      "Remaining 253\n",
      "Remaining 252\n",
      "Remaining 251\n",
      "Remaining 250\n",
      "Remaining 249\n",
      "Remaining 248\n",
      "Remaining 247\n",
      "Remaining 246\n",
      "Remaining 245\n",
      "Remaining 244\n",
      "Remaining 243\n",
      "Remaining 242\n",
      "Remaining 241\n",
      "Remaining 240\n",
      "Remaining 239\n",
      "Remaining 238\n",
      "Remaining 237\n",
      "Remaining 236\n",
      "Remaining 235\n",
      "Remaining 234\n",
      "Remaining 233\n",
      "Remaining 232\n",
      "Remaining 231\n",
      "Remaining 230\n",
      "Remaining 229\n",
      "Remaining 228\n",
      "Remaining 227\n",
      "Remaining 226\n",
      "Remaining 225\n",
      "Remaining 224\n",
      "Remaining 223\n",
      "Remaining 222\n",
      "Remaining 221\n",
      "Remaining 220\n",
      "Remaining 219\n",
      "Remaining 218\n",
      "Remaining 217\n",
      "Remaining 216\n",
      "Remaining 215\n",
      "Remaining 214\n",
      "Remaining 213\n",
      "Remaining 212\n",
      "Remaining 211\n",
      "Remaining 210\n",
      "Remaining 209\n",
      "Remaining 208\n",
      "Remaining 207\n",
      "Remaining 206\n",
      "Remaining 205\n",
      "Remaining 204\n",
      "Remaining 203\n",
      "Remaining 202\n",
      "Remaining 201\n",
      "Remaining 200\n",
      "Remaining 199\n",
      "Remaining 198\n",
      "Remaining 197\n",
      "Remaining 196\n",
      "Remaining 195\n",
      "Remaining 194\n",
      "Remaining 193\n",
      "Remaining 192\n",
      "Remaining 191\n",
      "Remaining 190\n",
      "Remaining 189\n",
      "Remaining 188\n",
      "Remaining 187\n",
      "Remaining 186\n",
      "Remaining 185\n",
      "Remaining 184\n",
      "Remaining 183\n",
      "Remaining 182\n",
      "Remaining 181\n",
      "Remaining 180\n",
      "Remaining 179\n",
      "Remaining 178\n",
      "Remaining 177\n",
      "Remaining 176\n",
      "Remaining 175\n",
      "Remaining 174\n",
      "Remaining 173\n",
      "Remaining 172\n",
      "Remaining 171\n",
      "Remaining 170\n",
      "Remaining 169\n",
      "Remaining 168\n",
      "Remaining 167\n",
      "Remaining 166\n",
      "Remaining 165\n",
      "Remaining 164\n",
      "Remaining 163\n",
      "Remaining 162\n",
      "Remaining 161\n",
      "Remaining 160\n",
      "Remaining 159\n",
      "Remaining 158\n",
      "Remaining 157\n",
      "Remaining 156\n",
      "Remaining 155\n",
      "Remaining 154\n",
      "Remaining 153\n",
      "Remaining 152\n",
      "Remaining 151\n",
      "Remaining 150\n",
      "Remaining 149\n",
      "Remaining 148\n",
      "Remaining 147\n",
      "Remaining 146\n",
      "Remaining 145\n",
      "Remaining 144\n",
      "Remaining 143\n",
      "Remaining 142\n",
      "Remaining 141\n",
      "Remaining 140\n",
      "Remaining 139\n",
      "Remaining 138\n",
      "Remaining 137\n",
      "Remaining 136\n",
      "Remaining 135\n",
      "Remaining 134\n",
      "Remaining 133\n",
      "Remaining 132\n",
      "Remaining 131\n",
      "Remaining 130\n",
      "Remaining 129\n",
      "Remaining 128\n",
      "Remaining 127\n",
      "Remaining 126\n",
      "Remaining 125\n",
      "Remaining 124\n",
      "Remaining 123\n",
      "Remaining 122\n",
      "Remaining 121\n",
      "Remaining 120\n",
      "Remaining 119\n",
      "Remaining 118\n",
      "Remaining 117\n",
      "Remaining 116\n",
      "Remaining 115\n",
      "Remaining 114\n",
      "Remaining 113\n",
      "Remaining 112\n",
      "Remaining 111\n",
      "Remaining 110\n",
      "Remaining 109\n",
      "Remaining 108\n",
      "Remaining 107\n",
      "Remaining 106\n",
      "Remaining 105\n",
      "Remaining 104\n",
      "Remaining 103\n",
      "Remaining 102\n",
      "Remaining 101\n",
      "Remaining 100\n",
      "Remaining 99\n",
      "Remaining 98\n",
      "Remaining 97\n",
      "Remaining 96\n",
      "Remaining 95\n",
      "Remaining 94\n",
      "Remaining 93\n",
      "Remaining 92\n",
      "Remaining 91\n",
      "Remaining 90\n",
      "Remaining 89\n",
      "Remaining 88\n",
      "Remaining 87\n",
      "Remaining 86\n",
      "Remaining 85\n",
      "Remaining 84\n",
      "Remaining 83\n",
      "Remaining 82\n",
      "Remaining 81\n",
      "Remaining 80\n",
      "Remaining 79\n",
      "Remaining 78\n",
      "Remaining 77\n",
      "Remaining 76\n",
      "Remaining 75\n",
      "Remaining 74\n",
      "Remaining 73\n",
      "Remaining 72\n",
      "Remaining 71\n",
      "Remaining 70\n",
      "Remaining 69\n",
      "Remaining 68\n",
      "Remaining 67\n",
      "Remaining 66\n",
      "Remaining 65\n",
      "Remaining 64\n",
      "Remaining 63\n",
      "Remaining 62\n",
      "Remaining 61\n",
      "Remaining 60\n",
      "Remaining 59\n",
      "Remaining 58\n",
      "Remaining 57\n",
      "Remaining 56\n",
      "Remaining 55\n",
      "Remaining 54\n",
      "Remaining 53\n",
      "Remaining 52\n",
      "Remaining 51\n",
      "Remaining 50\n",
      "Remaining 49\n",
      "Remaining 48\n",
      "Remaining 47\n",
      "Remaining 46\n",
      "Remaining 45\n",
      "Remaining 44\n",
      "Remaining 43\n",
      "Remaining 42\n",
      "Remaining 41\n",
      "Remaining 40\n",
      "Remaining 39\n",
      "Remaining 38\n",
      "Remaining 37\n",
      "Remaining 36\n",
      "Remaining 35\n",
      "Remaining 34\n",
      "Remaining 33\n",
      "Remaining 32\n",
      "Remaining 31\n",
      "Remaining 30\n",
      "Remaining 29\n",
      "Remaining 28\n",
      "Remaining 27\n",
      "Remaining 26\n",
      "Remaining 25\n",
      "Remaining 24\n",
      "Remaining 23\n",
      "Remaining 22\n",
      "Remaining 21\n",
      "Remaining 20\n",
      "Remaining 19\n",
      "Remaining 18\n",
      "Remaining 17\n",
      "Remaining 16\n",
      "Remaining 15\n",
      "Remaining 14\n",
      "Remaining 13\n",
      "Remaining 12\n",
      "Remaining 11\n",
      "Remaining 10\n",
      "Remaining 9\n",
      "Remaining 8\n",
      "Remaining 7\n",
      "Remaining 6\n",
      "Remaining 5\n",
      "Remaining 4\n",
      "Remaining 3\n",
      "Remaining 2\n",
      "Remaining 1\n"
     ]
    }
   ],
   "source": [
    "# Manually add dummy variables to allow us to train a model on a per country basis \n",
    "# while still including all information of the other countries\n",
    "grouped_transpose = grouped.T.copy()\n",
    "\n",
    "country_codes = list(set(grouped.index.get_level_values(0)))\n",
    "\n",
    "number_of_codes = len(country_codes)\n",
    "\n",
    "for code in country_codes:\n",
    "    print(f\"Remaining {number_of_codes}\")\n",
    "    for code_false in country_codes:\n",
    "        grouped_transpose[code, f\"code_{code_false}\"] = code == code_false\n",
    "    number_of_codes -= 1\n",
    "\n",
    "grouped_transpose = grouped_transpose.sort_index(axis=1)\n",
    "\n",
    "def convert_to_datetime(x):\n",
    "    return x.strip().split(' ')[0]\n",
    "\n",
    "index_dates = grouped_transpose.index.to_series().apply(convert_to_datetime)\n",
    "\n",
    "grouped_transpose.index = pd.to_datetime(index_dates)\n",
    "\n",
    "# This was already done before no need to do it again\n",
    "# grouped_transpose = grouped_transpose.replace('..', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output to JSON for repeat use\n",
    "grouped_transpose.to_json(Path('processed.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1973-01-01    2.613\n",
       "1974-01-01    2.552\n",
       "1975-01-01    2.506\n",
       "1976-01-01    2.472\n",
       "1977-01-01    2.446\n",
       "1978-01-01    2.425\n",
       "1979-01-01    2.408\n",
       "1980-01-01    2.392\n",
       "1981-01-01    2.377\n",
       "1982-01-01    2.364\n",
       "1983-01-01    2.353\n",
       "1984-01-01    2.342\n",
       "1985-01-01    2.332\n",
       "1986-01-01     2.32\n",
       "1987-01-01    2.307\n",
       "1988-01-01    2.291\n",
       "1989-01-01    2.272\n",
       "1990-01-01    2.303\n",
       "1991-01-01    2.314\n",
       "1992-01-01    2.277\n",
       "1993-01-01    2.226\n",
       "1994-01-01    2.125\n",
       "1995-01-01     2.19\n",
       "1996-01-01    2.153\n",
       "1997-01-01    2.144\n",
       "1998-01-01    1.957\n",
       "1999-01-01    1.869\n",
       "2000-01-01    1.904\n",
       "2001-01-01    1.833\n",
       "2002-01-01    1.763\n",
       "2003-01-01    1.747\n",
       "2004-01-01    1.683\n",
       "2005-01-01    1.777\n",
       "2006-01-01    1.909\n",
       "2007-01-01    1.928\n",
       "2008-01-01    1.935\n",
       "2009-01-01    1.919\n",
       "2010-01-01    1.941\n",
       "2011-01-01    1.962\n",
       "2012-01-01    2.028\n",
       "2013-01-01    2.117\n",
       "2014-01-01    2.148\n",
       "2015-01-01    1.972\n",
       "2016-01-01    1.953\n",
       "2017-01-01    1.839\n",
       "2018-01-01    1.587\n",
       "2019-01-01    1.486\n",
       "2020-01-01    1.325\n",
       "2021-01-01     1.18\n",
       "2022-01-01      NaN\n",
       "Name: Fertility rate, total (births per woman), dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_transpose['ABW']['Fertility rate, total (births per woman)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
